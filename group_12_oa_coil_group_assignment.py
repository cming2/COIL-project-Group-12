# -*- coding: utf-8 -*-
"""GROUP 12 OA COIL GROUP ASSIGNMENT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gBC5RhcGHEIHaBHkuvciHXI-Np8TJPzh
"""

!pip install yfinance
import pandas as pd
import numpy as np
import yfinance as yf

# Download USD/CHF data from Yahoo Finance
usd_chf = yf.download('CHF=X', start='2021-01-01', end='2024-06-30', interval='1d')

# Keep only the Close price, as 'Adj Close' might not be available due to auto_adjust behavior
usd_chf = usd_chf[['Close']]

# Reset the index so 'Date' is a column
usd_chf = usd_chf.reset_index()

# Show the first 5 rows
usd_chf.head()

import yfinance as yf
import pandas as pd

# Download USD/CHF data
usd_chf = yf.download('CHF=X', start='2021-01-01', end='2024-06-30', interval='1d', auto_adjust=False)

# Use 'Close' column instead of 'Adj Close'
usd_chf = usd_chf[['Close']]

# Reset the index so 'Date' is a column
usd_chf = usd_chf.reset_index()

# Show first 5 rows
usd_chf.head()

# Check how many rows you have
len(usd_chf)

# Calculate daily returns
usd_chf['Daily_Return'] = usd_chf['Close'].pct_change()

# Drop the first row because it will be NaN
usd_chf = usd_chf.dropna()

# Show first 5 rows with returns
usd_chf.head()

# Download US 10-year Treasury yield daily data
interest = yf.download('^TNX', start='2021-01-01', end='2024-06-30', interval='1d', auto_adjust=False)

# Keep only 'Close' and reset index
interest = interest[['Close']].reset_index()

# Rename column to 'Interest_Rate'
interest = interest.rename(columns={'Close': 'Interest_Rate'})

# Show first 5 rows
interest.head()

# Download S&P 500 daily data
sp500 = yf.download('^GSPC', start='2021-01-01', end='2024-06-30', interval='1d', auto_adjust=False)

# Keep only 'Close' and reset index
sp500 = sp500[['Close']].reset_index()

# Rename column
sp500 = sp500.rename(columns={'Close': 'SP500_Close'})

# Calculate daily returns
sp500['SP500_Return'] = sp500['SP500_Close'].pct_change()

# Drop first row (NaN)
sp500 = sp500.dropna()

# Show first 5 rows
sp500.head()

# Merge USD/CHF + Interest + SP500_Return
df = pd.merge(usd_chf, interest, on='Date', how='inner')
df = pd.merge(df, sp500[['Date','SP500_Return']], on='Date', how='inner')

# Check first 5 rows
df.head()

df.columns

# Rename the last column to 'SP500_Return'
df = df.rename(columns={df.columns[-1]: 'SP500_Return'})

# Check the columns
df.columns

df.head()

df.tail()

df.shape

!pip install fredapi
from fredapi import Fred

# Replace with your FRED API key
api_key = 'YOUR_API_KEY'
fred = Fred(api_key=api_key)

from fredapi import Fred

api_key = '978cfa22c41a135660cb70b21d132089'  # your API key
fred = Fred(api_key=api_key)

# Download US CPI (monthly)
cpi = fred.get_series('CPIAUCSL', observation_start='2021-01-01', observation_end='2024-06-30')

# Convert to DataFrame
cpi = cpi.to_frame().reset_index()
cpi.columns = ['Date', 'CPI']

# Convert Date to datetime
cpi['Date'] = pd.to_datetime(cpi['Date'])

# Calculate monthly % change (Inflation Rate)
cpi['Inflation_Rate'] = cpi['CPI'].pct_change()

# Drop first row (NaN)
cpi = cpi.dropna()

# Forward-fill monthly inflation to daily
cpi_daily = cpi.set_index('Date').resample('D').ffill().reset_index()

# Keep only Date and Inflation_Rate
cpi_daily = cpi_daily[['Date', 'Inflation_Rate']]

cpi_daily.head()

df = pd.merge(df, cpi_daily, on='Date', how='inner')
df.head()

df.head()      # first 5 rows
df.tail()      # last 5 rows
df.shape       # number of rows and columns
df.info()      # check data types and missing values

# Drop the duplicate date column (the tuple one)
df = df.drop(columns=[('Date', '')])

# Rename columns to simpler names
df = df.rename(columns={
    ('Close', 'CHF=X'): 'Close',
    ('Daily_Return', ''): 'Daily_Return',
    ('Interest_Rate', '^TNX'): 'Interest_Rate'
})

df.head()

df.columns.tolist()

df.columns = ['Date', 'Close', 'Daily_Return', 'Interest_Rate', 'SP500_Return', 'Inflation_Rate']

df.columns.tolist()

['Date', '(Date, )', '(Close, CHF=X)', '(Daily_Return, )', '(Interest_Rate, ^TNX)', 'SP500_Return', 'Inflation_Rate']

df.columns.tolist()

df.to_csv('cleaned_data.csv', index=False)

# List files in current directory to confirm
!ls

pd.read_csv('cleaned_data.csv').head()

import yfinance as yf
import pandas as pd

# 1. Download CHF/USD exchange rate
usd_chf = yf.download('CHF=X', start='2021-01-01', end='2024-06-30', interval='1d', auto_adjust=True)

# Ensure columns are flattened if they are MultiIndex (common with yfinance output)
if isinstance(usd_chf.columns, pd.MultiIndex):
    # Flatten the MultiIndex to a single level, joining elements with '_'
    usd_chf.columns = ['_'.join(col).strip() if col[1] else col[0] for col in usd_chf.columns.values]

# Reset the index to make 'Date' a regular column, and rename it explicitly
usd_chf = usd_chf.reset_index()
# The index from yfinance is typically named 'Date', so reset_index() will make a 'Date' column.
# The following rename is generally not needed for yfinance data, but included for robustness if 'index' appears.
if 'index' in usd_chf.columns:
    usd_chf.rename(columns={'index': 'Date'}, inplace=True)

# Select only 'Date' and the appropriate 'Close' column
# The 'Close' column might be named 'Close' or 'Close_CHF=X' after flattening.
if 'Close' in usd_chf.columns:
    selected_close_col = 'Close'
elif 'Close_CHF=X' in usd_chf.columns:
    selected_close_col = 'Close_CHF=X'
else:
    raise KeyError("Could not find a 'Close' column (or 'Close_CHF=X') in the USD/CHF data.")

usd_chf = usd_chf[['Date', selected_close_col]]
usd_chf.rename(columns={selected_close_col: 'Close'}, inplace=True)

# Ensure 'Date' is datetime
usd_chf['Date'] = pd.to_datetime(usd_chf['Date'])

# 2. Calculate daily returns
usd_chf['Daily_Return'] = usd_chf['Close'].pct_change()
usd_chf = usd_chf.dropna()

# 3. Handle Interest Rate and S&P500 DataFrames: ensure their column names are flat.
# The existing code already attempts to clean these, but let's re-confirm.
interest.columns = ['Date', 'Interest_Rate'] # This assumes 'interest' was properly loaded and only needs these two columns
sp500.columns = ['Date', 'SP500_Close', 'SP500_Return'] # This assumes 'sp500' was properly loaded and only needs these three columns

# Convert Date columns to datetime for all DataFrames
interest['Date'] = pd.to_datetime(interest['Date'])
sp500['Date'] = pd.to_datetime(sp500['Date'])
# cpi_daily['Date'] is already datetime

# 4. Merge datasets on Date
df = usd_chf.merge(interest[['Date', 'Interest_Rate']], on='Date', how='inner') \
             .merge(sp500[['Date', 'SP500_Return']], on='Date', how='inner') \
             .merge(cpi_daily[['Date', 'Inflation_Rate']], on='Date', how='inner')

# 5. Check for missing values
print("Missing values in each column:")
print(df.isnull().sum())

# 6. Save cleaned dataset for modeling
df.to_csv('cleaned_data.csv', index=False)
print("Cleaned dataset saved as 'cleaned_data.csv'. Shape:", df.shape)

# Optional: peek at first 5 rows
df.head()

# Assume you already have these DataFrames:
# df -> contains Close and Daily_Return
# interest -> interest rate DataFrame
# sp500 -> S&P500 DataFrame
# inflation -> CPI DataFrame

# Make sure all Date columns are datetime
df['Date'] = pd.to_datetime(df['Date'])
interest['Date'] = pd.to_datetime(interest['Date'])
sp500['Date'] = pd.to_datetime(sp500['Date'])
cpi_daily['Date'] = pd.to_datetime(cpi_daily['Date']) # Corrected from inflation to cpi_daily

# Merge everything on 'Date'
df = df.merge(interest, on='Date', how='inner') \
       .merge(sp500, on='Date', how='inner') \
       .merge(cpi_daily, on='Date', how='inner') # Corrected from inflation to cpi_daily

# Check missing values
print(df.isnull().sum())

# Save cleaned dataset
df.to_csv('cleaned_data.csv', index=False)
print("Cleaned dataset ready! Shape:", df.shape)

# Ensure 'Date' is datetime
df['Date'] = pd.to_datetime(df['Date'])

# Check for missing values
print(df.isnull().sum())

# Save cleaned dataset for the team
df.to_csv('cleaned_data.csv', index=False)
print("Data Manager work done! Shape:", df.shape)

df.to_csv('/content/cleaned_data.csv', index=False)

import pandas as pd
import os


if 'cleaned_data.csv' in os.listdir():
    print("✅ ¡El archivo existe! Cargando datos...")
    df = pd.read_csv('cleaned_data.csv')


    df['Date'] = pd.to_datetime(df['Date'])
    df = df.sort_values('Date')

    print(f"Datos listos. Tenemos {len(df)} días de datos.")
    print(df.head())
else:
    print("❌ Error: No encuentro 'cleaned_data.csv'. Asegúrate de haber ejecutado el código de la Data Manager primero.")

import os
os.listdir()

import pandas as pd

df = pd.read_csv('cleaned_data.csv')
df.head()

!pip install xgboost


import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.metrics import mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt


df = pd.read_csv('cleaned_data.csv')


df['Date'] = pd.to_datetime(df['Date'])
df = df.sort_values('Date')

print("Datos cargados correctamente. Filas:", len(df))
df.head()

y = df['Daily_Return']


features = ['Interest_Rate_x', 'SP500_Return_x', 'Inflation_Rate_x']
X = df[features]


split_point = int(len(df) * 0.80)

X_train = X.iloc[:split_point]
X_test = X.iloc[split_point:]
y_train = y.iloc[:split_point]
y_test = y.iloc[split_point:]

print(f"Training: {X_train.shape[0]} days")
print(f"Test: {X_test.shape[0]} days")

model = xgb.XGBRegressor(
    objective='reg:squarederror',
    n_estimators=100,
    learning_rate=0.1,
    max_depth=3,
    random_state=42
)


model.fit(X_train, y_train)

print("XGBoost model sucessfully trained!")

predictions = model.predict(X_test)


rmse = np.sqrt(mean_squared_error(y_test, predictions))
mae = mean_absolute_error(y_test, predictions)

print(f"Evaluation results (Test Set):")
print(f"RMSE (Root Mean Squared Error): {rmse:.5f}")
print(f"MAE (Mean Absolute Error): {mae:.5f}")


plt.figure(figsize=(12, 6))
plt.plot(y_test.values, label='Reality (Actual Returns)', alpha=0.7)
plt.plot(predictions, label='Prediction (XGBoost)', alpha=0.7, color='red')
plt.title("Return Prediction USD/CHF (Test Set)")
plt.legend()
plt.show()

!pip install shap

import shap

# Initialize SHAP TreeExplainer with the trained XGBoost model
explainer = shap.TreeExplainer(model)

# Calculate SHAP values for the test features
shap_values = explainer.shap_values(X_test)

# Generate a SHAP summary plot for overall feature importance (bar plot)
print("Generating SHAP summary plot (bar) for overall feature importance...")
shap.summary_plot(shap_values, X_test, plot_type="bar", show=False)
plt.title("SHAP Feature Importance (Bar Plot)")
plt.tight_layout()
plt.show()

# Generate a detailed SHAP summary plot for feature impact
print("Generating SHAP summary plot for detailed feature impact...")
shap.summary_plot(shap_values, X_test, show=False)
plt.title("SHAP Feature Impact")
plt.tight_layout()
plt.show()

"""The SHAP feature importance plot shows that Inflation Rate is the strongest contributor to the model’s predictions of daily currency returns, followed by the Interest Rate, while SP500 returns have the weakest impact.
Although the overall magnitudes are small, this reflects the nature of daily financial data, where currency returns are highly volatile and influenced by many unobservable short-run factors.

The SHAP summary plot indicates that higher inflation values tend to slightly increase the predicted return, suggesting some sensitivity of the currency to inflation changes. Interest rate movements also show a positive relationship with predicted returns, consistent with economic theory that higher interest rates attract foreign capital and strengthen a currency.
In contrast, S&P500 returns show minimal variation in SHAP values, implying that global equity market performance has limited explanatory power for daily currency return fluctuations.
"""